

# 概率论

~~~markdown
1. 概率：一个时间发生的次数和总数的比值，是衡量不确定事件的标准
		事件A发生的概率：P(A)=A频率/全集n
2. 乘法公式:P(AB) = P(A) * P(B)，AB事件必须相互独立
3. 加法公式:P(A+B) = P(A) + P(B)，AB时间必须相互独立
4. 条件概率:在事件B发生的情况下， 事件A发生的概率。P(A|B)
5. 广义上的乘法公式:P(AB) = P(A) * P(B|A) = P(B) * P(A|B)
6. 贝叶斯公式:P(A|B) = P(A)P(B|A)/P(B)
7. 全概率公式:P(B) = P(A1)P(B|A1)+P(A2)P(B|A2)+...+P(An)p(B|An)
~~~



# 朴素贝叶斯

~~~markdown
朴素：在给定类别的情况下，各个特征互相独立
贝叶斯公式：P(A|B) = P(A)P(B|A)/P(B)
方便理解：P(类别|特征) = P(类别)P(特征|类别)/P(特征)
真正的朴素贝叶斯：P(特征|类别) = P(特征)P(类别|特征)/P(类别)
~~~

| 帅？ | 性格好？ | 身高？ | 上进   | 嫁不嫁？ |
| ---- | -------- | ------ | ------ | -------- |
| 帅   | 不好     | 矮     | 不上进 | 不嫁     |
| 不帅 | 好       | 矮     | 上进   | 不嫁     |
| 帅   | 好       | 矮     | 上进   | 嫁       |
| 不帅 | 好       | 高     | 上进   | 嫁       |
| 帅   | 不好     | 矮     | 上进   | 不嫁     |
| 不帅 | 不好     | 矮     | 不上进 | 不嫁     |
| 帅   | 好       | 高     | 不上进 | 嫁       |
| 不帅 | 好       | 高     | 上进   | 嫁       |
| 帅   | 好       | 高     | 上进   | 嫁       |
| 不帅 | 不好     | 高     | 上进   | 嫁       |
| 帅   | 好       | 矮     | 不上进 | 不嫁     |
| 帅   | 好       | 矮     | 不上进 | 不嫁     |



![朴素贝叶斯](D:\TYUT教学资料\TYUT2022\笔记\.assets\朴素贝叶斯.png)



### 在Scikit-learn中有三个实现

~~~markdown
1. 高斯贝叶斯：数据集符合高斯分布的时候，用的较多
2. 伯努利贝叶斯：数据集符合伯努利分布的时候，用的较多
3. 多项式贝叶斯：数据集符合多项式分布的时候，用的较多
~~~

~~~python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB
from sklearn.preprocessing import MinMaxScaler

df = pd.read_csv('dating.txt',sep='\t',names=['salary','taobao','tv','result'])
X = df.iloc[:,:3]
Y = df.iloc[:,-1]
scaler = MinMaxScaler()
scaler.fit(X)
X = scaler.transform(X)

train_X,test_X,train_Y,test_Y = train_test_split(X,Y,test_size=0.2)
NB = GaussianNB()
NB.fit(train_X,train_Y)
print(NB.score(test_X,test_Y))
~~~

### 单词拼写检查

~~~markdown
用户输入一个单词，如果单词是正确的则原样输出，如果单词是错误的，则修正后输出
1. fave	have、face....
2. soomething someting
3. hae have
4. ture true
5. true true
~~~

~~~markdown
杰卡德距离：两个集合的交集除以并集
编辑距离：一个单词经过几次变换可以得到另外一个单词，变换的次数就是他们的距离
一次变换：
	1. 多一个字母
	2. 少一个字母
	3. 相邻的字母颠倒
	4. 错一个字母
1. 准备一个莎士比亚全集
2. 先判断用户输错了没，看用户输入的单词是否在词库中，在词库中，则认为用户输入正确，输出
3. 如果不在？找到编辑距离为1的词儿
4. 遍历这些单词，输出在文章中出现最多的单词。
~~~

### 垃圾邮件过滤

~~~markdown
1. 给定一封邮件，输出ta是否是垃圾邮件
~~~

#### 思路的产生

~~~markdown
1. 垃圾邮件和正常的邮件有没有区别？有
2. 垃圾邮件和正常邮件的主要区别在于邮件内容。
	发件人
	收件人
	主题
	附件
	内容
3. 组成内容的句子不一样
4. 组成句子的高频词不一样
~~~

### 开发流程

~~~markdown
1. 读取所有邮件，并且分词，统计前100个高频词作为特征
2. 遍历所有邮件，统计每个特征词在该邮件中出现了多少次，作为特征值构建X
3. 构建目标向量Y
4. 跑模型，评估模型，调参数
~~~

### 作业

~~~markdown
1. 单词拼写检查优化
2. 垃圾邮件过滤优化
3. 新闻分类--->自己从网上采集一些自己感兴趣的文本进行分类
4. 扩展作业：
	1. 中文版的单词拼写检查
~~~

# Numpy

~~~markdown
1. 科学计算的类库，由纯python编写，打破了GIL锁，所以效率很高

第三方的库：pip install numpy
~~~

## Numpy的架构设计

~~~markdown
1. numpy中最重要的是一个多维数组对象：NDarray
	1. 如何去创建一个NDarray
			nd = np.array(p_object, dtype=None, *args, **kwargs)
			p_object:python对象
			dtype:数据类型
			nd = np.zeros()# 创建一个全0填充的数组，一维可以传一个数字，除此以外传一个元组或者列表
			nd = np.ones()# 用法同上
	2. Ndarray有什么属性：
		1. nd.T：转置
		2. nd.size：返回元素个数
		3. nd.shape：返回数组的形状
		4. nd.dtype：返回数组的数据类型
		5. nd.ndim：返回数组的维度
	3. Ndarray有什么方法：
		nd.sum(axis=1) # 求和，axis的值：0代表每一列的和，1代表每一行的和。如果不写axis的值，那么整体求和。
		nd.min(axis=1) # 最小值，axis的值：0代表每一列的最小值，1代表每一行的最小值。如果不写axis的值，那么整体求最小值。
		nd.max(axis=0) # 最大值，axis的值：0代表每一列的最大值，1代表每一行的最大值。如果不写axis的值，那么整体求最大值。
		nd.var(axis=0) # 方差，axis的值：0代表每一列的方差，1代表每一行的方差。如果不写axis的值，那么整体求方差。
		nd.std() # 标准差，axis的值：0代表每一列的标准差，1代表每一行的标准差。如果不写axis的值，那么整体求标准差。
		nd.mean() # 平均值，axis的值：0代表每一列的平均值，1代表每一行的平均值。如果不写axis的值，那么整体求平均值。
		nd.prod() # 乘积，axis的值：0代表每一列的乘积，1代表每一行的乘积。如果不写axis的值，那么整体求乘积。
	4. 特殊的东西
		1. 切片
		2. 运算
https://www.numpy.org.cn
~~~

# Pandas

~~~markdown
1. python开发的用于数据处理的类库，非常的灵活，提供了大量的数据处理的工具

第三方：pip install
~~~

### Pandas的架构设计

~~~markdown
1. 一维：Series（不用）
2. 二维：DataFrame---最常用的没有之一
	1. 如何创建
		pd.DataFrame(l)
		pd.read_csv() # 类似的其他的read方法，读出来一样是DataFrame
3. 三维：Panel

中文官方文档：
https://www.pypandas.cn
~~~





### 自然数编码

~~~markdown
将字符串去重以后，把每个字符串都映射为一个自然数，从而让字符串可以进行运算
~~~



















